{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPAc12ea8n2dSIbmy6l1xg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Harmandeepkaur370/MINI-PROJECT-6/blob/main/untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2JskkvoIVj5",
        "outputId": "ac56ed3f-1e47-4b24-8b3a-236a4483b5cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File 'random_strings.txt' created with 1000 random strings.\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import string\n",
        "\n",
        "# Function to generate a random string of given length\n",
        "def random_string(length=12):\n",
        "    letters = string.ascii_letters + string.digits\n",
        "    return ''.join(random.choices(letters, k=length))\n",
        "\n",
        "# Generate 1000 lines of random strings\n",
        "with open(\"random_strings.txt\", \"w\") as f:\n",
        "    for _ in range(1000):\n",
        "        f.write(random_string() + \"\\n\")\n",
        "\n",
        "print(\"File 'random_strings.txt' created with 1000 random strings.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import string\n",
        "\n",
        "def random_string(length=100):\n",
        "    characters = string.ascii_letters + string.digits\n",
        "    return ''.join(random.choices(characters, k=length))\n",
        "\n",
        "target_size = 5 * 1024 * 1024  # 5 MB in bytes\n",
        "output_file = \"random_5MB.txt\"\n",
        "\n",
        "with open(output_file, \"w\") as f:\n",
        "    while f.tell() < target_size:\n",
        "        line = random_string(100) + \"\\n\"\n",
        "        f.write(line)\n",
        "\n",
        "print(f\"File '{output_file}' created with size approximately {os.path.getsize(output_file)} bytes.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROLYDuTDJ6ZH",
        "outputId": "3c1f7992-0360-4f95-bec8-e3f9077b99d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File 'random_5MB.txt' created with size approximately 5242910 bytes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import string\n",
        "\n",
        "def random_string(length=100):\n",
        "    chars = string.ascii_letters + string.digits\n",
        "    return ''.join(random.choices(chars, k=length))\n",
        "\n",
        "def create_file(filename, target_size=5 * 1024 * 1024):\n",
        "    with open(filename, 'w') as f:\n",
        "        while f.tell() < target_size:\n",
        "            line = random_string(100) + '\\n'\n",
        "            f.write(line)\n",
        "    print(f\"{filename} created with size {os.path.getsize(filename)} bytes\")\n",
        "\n",
        "# Generate 10 files\n",
        "for i in range(1, 11):\n",
        "    filename = f\"random_file_{i}.txt\"\n",
        "    create_file(filename)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkFNCltsKOk3",
        "outputId": "9f656e68-28d8-42a2-ca7d-f2359e44837d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "random_file_1.txt created with size 5242910 bytes\n",
            "random_file_2.txt created with size 5242910 bytes\n",
            "random_file_3.txt created with size 5242910 bytes\n",
            "random_file_4.txt created with size 5242910 bytes\n",
            "random_file_5.txt created with size 5242910 bytes\n",
            "random_file_6.txt created with size 5242910 bytes\n",
            "random_file_7.txt created with size 5242910 bytes\n",
            "random_file_8.txt created with size 5242910 bytes\n",
            "random_file_9.txt created with size 5242910 bytes\n",
            "random_file_10.txt created with size 5242910 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import string\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "def generate_random_line(line_length=100):\n",
        "    \"\"\"Generate a random alphanumeric string of given length.\"\"\"\n",
        "    chars = string.ascii_letters + string.digits + \"    \"  # include spaces for variety\n",
        "    return ''.join(random.choices(chars, k=line_length)) + '\\n'\n",
        "\n",
        "def create_large_file(filename, size_gb, line_length=100):\n",
        "    \"\"\"\n",
        "    Create a file with random string lines until the file size reaches approx size_gb GB.\n",
        "\n",
        "    Args:\n",
        "        filename (str): File name to create.\n",
        "        size_gb (int): Size of the file in gigabytes.\n",
        "        line_length (int): Length of each random string line.\n",
        "    \"\"\"\n",
        "    target_size = size_gb * 1024**3  # bytes\n",
        "    total_written = 0\n",
        "    buffer_size = 1024 * 1024  # 1 MB buffer approximate\n",
        "\n",
        "    print(f\"Creating file {filename} with size {size_gb} GB...\")\n",
        "\n",
        "    with open(filename, 'w', encoding='utf-8') as f:\n",
        "        while total_written < target_size:\n",
        "            lines = []\n",
        "            chunk_size = 0\n",
        "            # Write batches of lines approx 1MB at a time\n",
        "            while chunk_size < buffer_size and total_written + chunk_size < target_size:\n",
        "                line = generate_random_line(line_length)\n",
        "                lines.append(line)\n",
        "                chunk_size += len(line.encode('utf-8'))\n",
        "            f.writelines(lines)\n",
        "            total_written += chunk_size\n",
        "\n",
        "    actual_size = os.path.getsize(filename) / (1024**3)\n",
        "    print(f\"Finished creating {filename}: actual size {actual_size:.2f} GB\")\n",
        "\n",
        "def convert_file_to_uppercase(source_path, dest_path=None):\n",
        "    \"\"\"\n",
        "    Convert the contents of the file at source_path to uppercase.\n",
        "    Writes output to dest_path if given, else overwrites source_path safely.\n",
        "\n",
        "    Args:\n",
        "        source_path (str): Path to the file to convert.\n",
        "        dest_path (str or None): Path to output file. If None, overwrite source_path.\n",
        "    \"\"\"\n",
        "    if dest_path is None:\n",
        "        dest_path = source_path + '.tmp'\n",
        "\n",
        "    print(f\"Converting {source_path} to uppercase...\")\n",
        "\n",
        "    with open(source_path, 'r', encoding='utf-8') as src, open(dest_path, 'w', encoding='utf-8') as dst:\n",
        "        for line in src:\n",
        "            dst.write(line.upper())\n",
        "\n",
        "    if dest_path != source_path:\n",
        "        os.replace(dest_path, source_path)\n",
        "\n",
        "    print(f\"Finished converting {source_path}.\")\n",
        "\n",
        "def convert_files_sequential(file_paths):\n",
        "    \"\"\"\n",
        "    Convert all files in file_paths to uppercase sequentially.\n",
        "    \"\"\"\n",
        "    print(\"Starting sequential conversion to uppercase...\")\n",
        "    for path in file_paths:\n",
        "        convert_file_to_uppercase(path)\n",
        "    print(\"Sequential conversion complete.\")\n",
        "\n",
        "def convert_files_parallel(file_paths, max_workers=None):\n",
        "    \"\"\"\n",
        "    Convert all files in file_paths to uppercase in parallel using threads.\n",
        "\n",
        "    Args:\n",
        "        file_paths (list of str): List of file paths.\n",
        "        max_workers (int or None): Max worker threads for parallel processing.\n",
        "    \"\"\"\n",
        "    print(\"Starting parallel conversion to uppercase using multithreading...\")\n",
        "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
        "        futures = {executor.submit(convert_file_to_uppercase, path): path for path in file_paths}\n",
        "        for future in as_completed(futures):\n",
        "            path = futures[future]\n",
        "            try:\n",
        "                future.result()\n",
        "            except Exception as e:\n",
        "                print(f\"Error converting file {path}: {e}\")\n",
        "    print(\"Parallel conversion complete.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Define filenames and sizes\n",
        "    files_and_sizes = [\n",
        "        (\"file_1GB.txt\", 1),\n",
        "        (\"file_2GB.txt\", 2),\n",
        "        (\"file_3GB.txt\", 3),\n",
        "        (\"file_4GB.txt\", 4),\n",
        "        (\"file_5GB.txt\", 5),\n",
        "    ]\n",
        "\n",
        "    # Step 1: Create files (comment out if already created)\n",
        "    for filename, size in files_and_sizes:\n",
        "        create_large_file(filename, size)\n",
        "\n",
        "    # Step 2: Convert files sequentially to uppercase\n",
        "    sequential_files = [f[0] for f in files_and_sizes]\n",
        "    convert_files_sequential(sequential_files)\n",
        "\n",
        "    # Optionally rename sequential converted files back if needed (already in place)\n",
        "\n",
        "    # Step 3: Convert files in parallel (use different output names to preserve originals if wanted)\n",
        "    # Here we convert sequentially uppercased files again to uppercase (idempotent), or use original files\n",
        "    # For demo purposes, reconvert same files\n",
        "    convert_files_parallel(sequential_files)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zkyhzNyTh9T",
        "outputId": "7af44a3b-56be-4b79-8d54-778d253fee2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating file file_1GB.txt with size 1 GB...\n",
            "Finished creating file_1GB.txt: actual size 1.00 GB\n",
            "Creating file file_2GB.txt with size 2 GB...\n",
            "Finished creating file_2GB.txt: actual size 2.00 GB\n",
            "Creating file file_3GB.txt with size 3 GB...\n",
            "Finished creating file_3GB.txt: actual size 3.00 GB\n",
            "Creating file file_4GB.txt with size 4 GB...\n",
            "Finished creating file_4GB.txt: actual size 4.00 GB\n",
            "Creating file file_5GB.txt with size 5 GB...\n",
            "Finished creating file_5GB.txt: actual size 5.00 GB\n",
            "Starting sequential conversion to uppercase...\n",
            "Converting file_1GB.txt to uppercase...\n",
            "Finished converting file_1GB.txt.\n",
            "Converting file_2GB.txt to uppercase...\n",
            "Finished converting file_2GB.txt.\n",
            "Converting file_3GB.txt to uppercase...\n",
            "Finished converting file_3GB.txt.\n",
            "Converting file_4GB.txt to uppercase...\n",
            "Finished converting file_4GB.txt.\n",
            "Converting file_5GB.txt to uppercase...\n",
            "Finished converting file_5GB.txt.\n",
            "Sequential conversion complete.\n",
            "Starting parallel conversion to uppercase using multithreading...\n",
            "Converting file_1GB.txt to uppercase...\n",
            "Converting file_2GB.txt to uppercase...\n",
            "Converting file_3GB.txt to uppercase...\n",
            "Converting file_4GB.txt to uppercase...\n",
            "Converting file_5GB.txt to uppercase...\n",
            "Finished converting file_1GB.txt.\n",
            "Finished converting file_2GB.txt.\n",
            "Finished converting file_3GB.txt.\n",
            "Finished converting file_4GB.txt.\n",
            "Finished converting file_5GB.txt.\n",
            "Parallel conversion complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install icrawler\n",
        "!pip install httpx==0.23.3\n",
        "\n",
        "\n",
        "\n",
        "from icrawler.builtin import GoogleImageCrawler\n",
        "\n",
        "def download_cat_images():\n",
        "    crawler = GoogleImageCrawler(storage={'root_dir': 'cat_images'})\n",
        "    crawler.crawl(keyword='cat', max_num=10)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    download_cat_images()\n",
        "    print(\"Downloaded 10 cat images into 'cat_images' folder.\")\n"
      ],
      "metadata": {
        "id": "3CHmTwEEMnCw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51ef2848-6080-49b5-9ff8-2be4de6c43d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: icrawler in /usr/local/lib/python3.11/dist-packages (0.6.10)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from icrawler) (4.13.4)\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.11/dist-packages (from icrawler) (0.0.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from icrawler) (5.4.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from icrawler) (11.2.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from icrawler) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from icrawler) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from icrawler) (1.17.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->icrawler) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->icrawler) (4.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->icrawler) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->icrawler) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->icrawler) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->icrawler) (2025.4.26)\n",
            "Requirement already satisfied: httpx==0.23.3 in /usr/local/lib/python3.11/dist-packages (0.23.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx==0.23.3) (2025.4.26)\n",
            "Requirement already satisfied: httpcore<0.17.0,>=0.15.0 in /usr/local/lib/python3.11/dist-packages (from httpx==0.23.3) (0.16.3)\n",
            "Requirement already satisfied: rfc3986<2,>=1.3 in /usr/local/lib/python3.11/dist-packages (from rfc3986[idna2008]<2,>=1.3->httpx==0.23.3) (1.5.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx==0.23.3) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore<0.17.0,>=0.15.0->httpx==0.23.3) (0.14.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from httpcore<0.17.0,>=0.15.0->httpx==0.23.3) (4.9.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from rfc3986[idna2008]<2,>=1.3->httpx==0.23.3) (3.10)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->httpcore<0.17.0,>=0.15.0->httpx==0.23.3) (4.14.0)\n",
            "Downloaded 10 cat images into 'cat_images' folder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install pytube using pip if not already installed\n",
        "# pip install pytube\n",
        "!pip install pytube\n",
        "!python download_ml_videos.py\n",
        "\n",
        "!pip install --upgrade pytube\n",
        "!pip install yt-dlp\n",
        "# Required package: yt-dlp\n",
        "# Install using: pip install yt-dlp\n",
        "\n",
        "import subprocess\n",
        "\n",
        "def download_machine_learning_videos(max_videos=10):\n",
        "    # Search YouTube using yt-dlp and extract URLs (requires ffmpeg for best results)\n",
        "    print(\"Searching for Machine Learning videos on YouTube...\")\n",
        "\n",
        "    # Use yt-dlp to fetch the top video URLs (without downloading yet)\n",
        "    command = [\n",
        "        \"yt-dlp\",\n",
        "        f\"ytsearch{max_videos}:Machine Learning\",\n",
        "        \"--get-id\"\n",
        "    ]\n",
        "\n",
        "    try:\n",
        "        result = subprocess.run(command, capture_output=True, text=True, check=True)\n",
        "        video_ids = result.stdout.strip().split(\"\\n\")\n",
        "        print(f\"Found {len(video_ids)} videos. Starting downloads...\\n\")\n",
        "\n",
        "        for i, video_id in enumerate(video_ids, 1):\n",
        "            video_url = f\"https://www.youtube.com/watch?v={video_id}\"\n",
        "            print(f\"[{i}/{max_videos}] Downloading: {video_url}\")\n",
        "            subprocess.run([\"yt-dlp\", \"-f\", \"mp4\", \"-o\", \"downloads/%(title)s.%(ext)s\", video_url])\n",
        "            print(\"Download complete.\\n\")\n",
        "\n",
        "        print(\"✅ All videos downloaded successfully.\")\n",
        "\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(\"❌ Failed to search or download videos.\")\n",
        "        print(\"Error:\", e.stderr)\n",
        "\n",
        "# Run the downloader\n",
        "download_machine_learning_videos(10)\n"
      ],
      "metadata": {
        "id": "x_p8f67ipGUk",
        "outputId": "5a6a89f4-baea-4f21-cc6f-fa6c417f51ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytube in /usr/local/lib/python3.11/dist-packages (15.0.0)\n",
            "python3: can't open file '/content/download_ml_videos.py': [Errno 2] No such file or directory\n",
            "Requirement already satisfied: pytube in /usr/local/lib/python3.11/dist-packages (15.0.0)\n",
            "Requirement already satisfied: yt-dlp in /usr/local/lib/python3.11/dist-packages (2025.6.9)\n",
            "Searching for Machine Learning videos on YouTube...\n",
            "Found 10 videos. Starting downloads...\n",
            "\n",
            "[1/10] Downloading: https://www.youtube.com/watch?v=i_LwzRVP7bg\n",
            "Download complete.\n",
            "\n",
            "[2/10] Downloading: https://www.youtube.com/watch?v=E0Hmnixke2g\n",
            "Download complete.\n",
            "\n",
            "[3/10] Downloading: https://www.youtube.com/watch?v=PeMlggyqz0Y\n",
            "Download complete.\n",
            "\n",
            "[4/10] Downloading: https://www.youtube.com/watch?v=ukzFI9rgwfU\n",
            "Download complete.\n",
            "\n",
            "[5/10] Downloading: https://www.youtube.com/watch?v=PcbuKRNtCUc\n",
            "Download complete.\n",
            "\n",
            "[6/10] Downloading: https://www.youtube.com/watch?v=9vM4p9NN0Ts\n",
            "Download complete.\n",
            "\n",
            "[7/10] Downloading: https://www.youtube.com/watch?v=h0e2HAPTGF4\n",
            "Download complete.\n",
            "\n",
            "[8/10] Downloading: https://www.youtube.com/watch?v=qYNweeDHiyU\n",
            "Download complete.\n",
            "\n",
            "[9/10] Downloading: https://www.youtube.com/watch?v=R5xL0sOxMh0\n",
            "Download complete.\n",
            "\n",
            "[10/10] Downloading: https://www.youtube.com/watch?v=0YdpwSYMY6I\n",
            "Download complete.\n",
            "\n",
            "✅ All videos downloaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "from moviepy.editor import VideoFileClip\n",
        "\n",
        "def download_machine_learning_videos(max_videos=10):\n",
        "    os.makedirs(\"downloads\", exist_ok=True)\n",
        "    os.makedirs(\"audios\", exist_ok=True)\n",
        "\n",
        "    print(\"🔍 Searching for Machine Learning videos on YouTube...\")\n",
        "\n",
        "    # Step 1: Get top video IDs via yt-dlp\n",
        "    search_command = [\n",
        "        \"yt-dlp\",\n",
        "        f\"ytsearch{max_videos}:Machine Learning\",\n",
        "        \"--get-id\"\n",
        "    ]\n",
        "\n",
        "    result = subprocess.run(search_command, capture_output=True, text=True)\n",
        "    video_ids = result.stdout.strip().split(\"\\n\")\n",
        "\n",
        "    print(f\"📹 Found {len(video_ids)} videos. Downloading...\\n\")\n",
        "\n",
        "    for i, video_id in enumerate(video_ids, 1):\n",
        "        video_url = f\"https://www.youtube.com/watch?v={video_id}\"\n",
        "        print(f\"[{i}/{max_videos}] Downloading: {video_url}\")\n",
        "        subprocess.run([\n",
        "            \"yt-dlp\", \"-f\", \"mp4\",\n",
        "            \"-o\", f\"downloads/%(title)s.%(ext)s\",\n",
        "            video_url\n",
        "        ])\n",
        "\n",
        "    print(\"\\n✅ Videos downloaded. Starting audio extraction...\\n\")\n",
        "\n",
        "    # Step 2: Convert each video to audio\n",
        "    for filename in os.listdir(\"downloads\"):\n",
        "        if filename.endswith(\".mp4\"):\n",
        "            video_path = os.path.join(\"downloads\", filename)\n",
        "            audio_path = os.path.join(\"audios\", os.path.splitext(filename)[0] + \".mp3\")\n",
        "\n",
        "            try:\n",
        "                print(f\"🎵 Converting: {filename} -> {audio_path}\")\n",
        "                video_clip = VideoFileClip(video_path)\n",
        "                video_clip.audio.write_audiofile(audio_path)\n",
        "                video_clip.close()\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Failed to convert {filename}: {e}\")\n",
        "\n",
        "    print(\"\\n🎧 All videos converted to audio and saved in 'audios/' folder.\")\n",
        "\n",
        "# Run everything\n",
        "download_machine_learning_videos(10)\n"
      ],
      "metadata": {
        "id": "B3m8ebMTtgzr",
        "outputId": "33787ae8-0b97-4923-d686-c73b222ca5d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.11/dist-packages/moviepy/video/io/sliders.py:61: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if event.key is 'enter':\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Searching for Machine Learning videos on YouTube...\n",
            "📹 Found 10 videos. Downloading...\n",
            "\n",
            "[1/10] Downloading: https://www.youtube.com/watch?v=i_LwzRVP7bg\n",
            "[2/10] Downloading: https://www.youtube.com/watch?v=E0Hmnixke2g\n",
            "[3/10] Downloading: https://www.youtube.com/watch?v=ukzFI9rgwfU\n",
            "[4/10] Downloading: https://www.youtube.com/watch?v=PeMlggyqz0Y\n",
            "[5/10] Downloading: https://www.youtube.com/watch?v=tmB5JIX3Lxk\n",
            "[6/10] Downloading: https://www.youtube.com/watch?v=0YdpwSYMY6I\n",
            "[7/10] Downloading: https://www.youtube.com/watch?v=qYNweeDHiyU\n",
            "[8/10] Downloading: https://www.youtube.com/watch?v=9vM4p9NN0Ts\n",
            "[9/10] Downloading: https://www.youtube.com/watch?v=R5xL0sOxMh0\n",
            "[10/10] Downloading: https://www.youtube.com/watch?v=bmmQA8A-yUA\n",
            "\n",
            "✅ Videos downloaded. Starting audio extraction...\n",
            "\n",
            "🎵 Converting: All Machine Learning algorithms explained in 17 min.mp4 -> audios/All Machine Learning algorithms explained in 17 min.mp3\n",
            "MoviePy - Writing audio in audios/All Machine Learning algorithms explained in 17 min.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "🎵 Converting: #3 Linear Regression in Machine Learning Part-2 ｜ Machine Learning Full Course ｜ Tpoint Tech.mp4 -> audios/#3 Linear Regression in Machine Learning Part-2 ｜ Machine Learning Full Course ｜ Tpoint Tech.mp3\n",
            "MoviePy - Writing audio in audios/#3 Linear Regression in Machine Learning Part-2 ｜ Machine Learning Full Course ｜ Tpoint Tech.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "🎵 Converting: Machine Learning in 2024 – Beginner's Course.mp4 -> audios/Machine Learning in 2024 – Beginner's Course.mp3\n",
            "MoviePy - Writing audio in audios/Machine Learning in 2024 – Beginner's Course.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "🎵 Converting: Essential Machine Learning and AI Concepts Animated.mp4 -> audios/Essential Machine Learning and AI Concepts Animated.mp3\n",
            "MoviePy - Writing audio in audios/Essential Machine Learning and AI Concepts Animated.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "🎵 Converting: Machine Learning for Everybody – Full Course.mp4 -> audios/Machine Learning for Everybody – Full Course.mp3\n",
            "MoviePy - Writing audio in audios/Machine Learning for Everybody – Full Course.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "🎵 Converting: All Machine Learning Models Clearly Explained!.mp4 -> audios/All Machine Learning Models Clearly Explained!.mp3\n",
            "MoviePy - Writing audio in audios/All Machine Learning Models Clearly Explained!.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "🎵 Converting: Intro to Machine Learning featuring Generative AI.mp4 -> audios/Intro to Machine Learning featuring Generative AI.mp3\n",
            "MoviePy - Writing audio in audios/Intro to Machine Learning featuring Generative AI.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "🎵 Converting: Machine Learning Explained in 100 Seconds.mp4 -> audios/Machine Learning Explained in 100 Seconds.mp3\n",
            "MoviePy - Writing audio in audios/Machine Learning Explained in 100 Seconds.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "🎵 Converting: Stanford CS229 I Machine Learning I Building Large Language Models (LLMs).mp4 -> audios/Stanford CS229 I Machine Learning I Building Large Language Models (LLMs).mp3\n",
            "MoviePy - Writing audio in audios/Stanford CS229 I Machine Learning I Building Large Language Models (LLMs).mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "🎵 Converting: AI, Machine Learning, Deep Learning and Generative AI Explained.mp4 -> audios/AI, Machine Learning, Deep Learning and Generative AI Explained.mp3\n",
            "MoviePy - Writing audio in audios/AI, Machine Learning, Deep Learning and Generative AI Explained.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "🎵 Converting: Machine Learning ｜ What Is Machine Learning？ ｜ Introduction To Machine Learning ｜ 2024 ｜ Simplilearn.mp4 -> audios/Machine Learning ｜ What Is Machine Learning？ ｜ Introduction To Machine Learning ｜ 2024 ｜ Simplilearn.mp3\n",
            "MoviePy - Writing audio in audios/Machine Learning ｜ What Is Machine Learning？ ｜ Introduction To Machine Learning ｜ 2024 ｜ Simplilearn.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "🎵 Converting: 11. Introduction to Machine Learning.mp4 -> audios/11. Introduction to Machine Learning.mp3\n",
            "MoviePy - Writing audio in audios/11. Introduction to Machine Learning.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                       "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "\n",
            "🎧 All videos converted to audio and saved in 'audios/' folder.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import threading\n",
        "import subprocess\n",
        "from queue import Queue\n",
        "from moviepy.editor import VideoFileClip\n",
        "\n",
        "NUM_VIDEOS = 100\n",
        "NUM_WORKERS = 4  # Number of threads for audio conversion\n",
        "\n",
        "DOWNLOAD_DIR = \"downloads\"\n",
        "AUDIO_DIR = \"audios\"\n",
        "\n",
        "os.makedirs(DOWNLOAD_DIR, exist_ok=True)\n",
        "os.makedirs(AUDIO_DIR, exist_ok=True)\n",
        "\n",
        "video_queue = Queue()\n",
        "\n",
        "# ------------------------------------\n",
        "# Producer: Download videos with yt-dlp\n",
        "# ------------------------------------\n",
        "def download_videos(query=\"Machine Learning\", max_videos=NUM_VIDEOS):\n",
        "    print(f\"🔍 Searching for top {max_videos} '{query}' videos on YouTube...\")\n",
        "\n",
        "    # Get video IDs\n",
        "    command = [\"yt-dlp\", f\"ytsearch{max_videos}:{query}\", \"--get-id\"]\n",
        "    result = subprocess.run(command, capture_output=True, text=True)\n",
        "    video_ids = result.stdout.strip().split(\"\\n\")\n",
        "\n",
        "    print(f\"📥 Found {len(video_ids)} videos. Starting downloads...\\n\")\n",
        "\n",
        "    for i, video_id in enumerate(video_ids, 1):\n",
        "        video_url = f\"https://www.youtube.com/watch?v={video_id}\"\n",
        "        print(f\"[{i}/{max_videos}] Downloading: {video_url}\")\n",
        "        try:\n",
        "            result = subprocess.run([\n",
        "                \"yt-dlp\", \"-f\", \"mp4\", \"-o\", f\"{DOWNLOAD_DIR}/%(title)s.%(ext)s\", video_url\n",
        "            ], capture_output=True, text=True)\n",
        "\n",
        "            # Find downloaded file\n",
        "            for line in result.stderr.splitlines():\n",
        "                if \"[download] Destination:\" in line:\n",
        "                    file_path = line.split(\"Destination:\")[1].strip()\n",
        "                    if os.path.exists(file_path):\n",
        "                        video_queue.put(file_path)\n",
        "                        print(f\"✅ Downloaded: {file_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error downloading {video_url}: {e}\")\n",
        "\n",
        "    print(\"🚀 All videos queued for conversion.\\n\")\n",
        "\n",
        "# ------------------------------------\n",
        "# Consumer: Convert downloaded videos to audio\n",
        "# ------------------------------------\n",
        "def audio_worker():\n",
        "    while True:\n",
        "        video_path = video_queue.get()\n",
        "        if video_path is None:\n",
        "            break  # Sentinel value to stop thread\n",
        "\n",
        "        try:\n",
        "            filename = os.path.basename(video_path)\n",
        "            audio_path = os.path.join(AUDIO_DIR, os.path.splitext(filename)[0] + \".mp3\")\n",
        "\n",
        "            print(f\"🎵 Converting to audio: {filename}\")\n",
        "            video_clip = VideoFileClip(video_path)\n",
        "            video_clip.audio.write_audiofile(audio_path, verbose=False, logger=None)\n",
        "            video_clip.close()\n",
        "            print(f\"🎧 Saved audio to: {audio_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error converting {video_path}: {e}\")\n",
        "        finally:\n",
        "            video_queue.task_done()\n",
        "\n",
        "# ------------------------------------\n",
        "# Main Execution\n",
        "# ------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    # Start audio conversion worker threads\n",
        "    for _ in range(NUM_WORKERS):\n",
        "        threading.Thread(target=audio_worker, daemon=True).start()\n",
        "\n",
        "    # Start video download (producer)\n",
        "    download_videos()\n",
        "\n",
        "    # Wait until all videos are converted\n",
        "    video_queue.join()\n",
        "\n",
        "    # Stop all worker threads\n",
        "    for _ in range(NUM_WORKERS):\n",
        "        video_queue.put(None)\n",
        "\n",
        "    print(\"\\n✅ Pipeline complete: All videos downloaded and converted to audio.\")\n"
      ],
      "metadata": {
        "id": "nEttlZ2tyTqY",
        "outputId": "4ec8ef49-c071-457c-a168-ee2ff303f029",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Searching for top 100 'Machine Learning' videos on YouTube...\n",
            "📥 Found 100 videos. Starting downloads...\n",
            "\n",
            "[1/100] Downloading: https://www.youtube.com/watch?v=E0Hmnixke2g\n",
            "[2/100] Downloading: https://www.youtube.com/watch?v=i_LwzRVP7bg\n",
            "[3/100] Downloading: https://www.youtube.com/watch?v=ukzFI9rgwfU\n",
            "[4/100] Downloading: https://www.youtube.com/watch?v=PeMlggyqz0Y\n",
            "[5/100] Downloading: https://www.youtube.com/watch?v=9vM4p9NN0Ts\n",
            "[6/100] Downloading: https://www.youtube.com/watch?v=0YdpwSYMY6I\n",
            "[7/100] Downloading: https://www.youtube.com/watch?v=qYNweeDHiyU\n",
            "[8/100] Downloading: https://www.youtube.com/watch?v=bmmQA8A-yUA\n",
            "[9/100] Downloading: https://www.youtube.com/watch?v=R5xL0sOxMh0\n",
            "[10/100] Downloading: https://www.youtube.com/watch?v=tmB5JIX3Lxk\n",
            "[11/100] Downloading: https://www.youtube.com/watch?v=vdRp_w9f-qM\n",
            "[12/100] Downloading: https://www.youtube.com/watch?v=h0e2HAPTGF4\n",
            "[13/100] Downloading: https://www.youtube.com/watch?v=Fa_V9fP2tpU\n",
            "[14/100] Downloading: https://www.youtube.com/watch?v=4RixMPF4xis\n",
            "[15/100] Downloading: https://www.youtube.com/watch?v=PcbuKRNtCUc\n",
            "[16/100] Downloading: https://www.youtube.com/watch?v=uyOMOIEIRMI\n",
            "[17/100] Downloading: https://www.youtube.com/watch?v=9gGnTQTYNaE\n",
            "[18/100] Downloading: https://www.youtube.com/watch?v=7eh4d6sabA0\n",
            "[19/100] Downloading: https://www.youtube.com/watch?v=0B5eIE_1vpU\n",
            "[20/100] Downloading: https://www.youtube.com/watch?v=V_xro1bcAuA\n",
            "[21/100] Downloading: https://www.youtube.com/watch?v=z-EtmaFJieY\n",
            "[22/100] Downloading: https://www.youtube.com/watch?v=q6kJ71tEYqM\n",
            "[23/100] Downloading: https://www.youtube.com/watch?v=5q87K1WaoFI\n",
            "[24/100] Downloading: https://www.youtube.com/watch?v=SmZmBKc7Lrs\n",
            "[25/100] Downloading: https://www.youtube.com/watch?v=GwIo3gDZCVQ\n",
            "[26/100] Downloading: https://www.youtube.com/watch?v=7IgVGSaQPaw\n",
            "[27/100] Downloading: https://www.youtube.com/watch?v=PopKlyqTPAI\n",
            "[28/100] Downloading: https://www.youtube.com/watch?v=hDKCxebp88A\n",
            "[29/100] Downloading: https://www.youtube.com/watch?v=EuBBz3bI-aA\n",
            "[30/100] Downloading: https://www.youtube.com/watch?v=JxgmHe2NyeY\n",
            "[31/100] Downloading: https://www.youtube.com/watch?v=-8qzzN7CWxA\n",
            "[32/100] Downloading: https://www.youtube.com/watch?v=qNxrPri1V0I\n",
            "[33/100] Downloading: https://www.youtube.com/watch?v=KgolhE7p-KY\n",
            "[34/100] Downloading: https://www.youtube.com/watch?v=_3pgLrYWZfo\n",
            "[35/100] Downloading: https://www.youtube.com/watch?v=yN7ypxC7838\n",
            "[36/100] Downloading: https://www.youtube.com/watch?v=aircAruvnKk\n",
            "[37/100] Downloading: https://www.youtube.com/watch?v=Gv9_4yMHFhI\n",
            "[38/100] Downloading: https://www.youtube.com/watch?v=NWONeJKn6kc\n",
            "[39/100] Downloading: https://www.youtube.com/watch?v=LB0kC0SkfeE\n",
            "[40/100] Downloading: https://www.youtube.com/watch?v=7gEzEAIELgQ\n",
            "[41/100] Downloading: https://www.youtube.com/watch?v=qPUYBX0C6ic\n",
            "[42/100] Downloading: https://www.youtube.com/watch?v=FbtYxPUrhq8\n",
            "[43/100] Downloading: https://www.youtube.com/watch?v=uZt95OZ4WUU\n",
            "[44/100] Downloading: https://www.youtube.com/watch?v=_AVBG6pgPhs\n",
            "[45/100] Downloading: https://www.youtube.com/watch?v=_J7HzClh4mo\n",
            "[46/100] Downloading: https://www.youtube.com/watch?v=g6Cyw3prtHY\n",
            "[47/100] Downloading: https://www.youtube.com/watch?v=8xUher8-5_Q\n",
            "[48/100] Downloading: https://www.youtube.com/watch?v=Bx4BYXOE9SQ\n",
            "[49/100] Downloading: https://www.youtube.com/watch?v=RG6pxTDNqik\n",
            "[50/100] Downloading: https://www.youtube.com/watch?v=29ZQ3TDGgRQ\n",
            "[51/100] Downloading: https://www.youtube.com/watch?v=QghjaS0WQQU\n",
            "[52/100] Downloading: https://www.youtube.com/watch?v=59bMh59JQDo\n",
            "[53/100] Downloading: https://www.youtube.com/watch?v=Rk3GGmcmYk0\n",
            "[54/100] Downloading: https://www.youtube.com/watch?v=xe9W0V12sgY\n",
            "[55/100] Downloading: https://www.youtube.com/watch?v=c0ySgqymARY\n",
            "[56/100] Downloading: https://www.youtube.com/watch?v=URtF_UHYBSo\n",
            "[57/100] Downloading: https://www.youtube.com/watch?v=BRq4N8VQ_Lo\n",
            "[58/100] Downloading: https://www.youtube.com/watch?v=600k_das5rc\n",
            "[59/100] Downloading: https://www.youtube.com/watch?v=Y3nHkcqXwow\n",
            "[60/100] Downloading: https://www.youtube.com/watch?v=RF53NPPhBmE\n",
            "[61/100] Downloading: https://www.youtube.com/watch?v=7gEzEAIELgQ\n",
            "[62/100] Downloading: https://www.youtube.com/watch?v=NWONeJKn6kc\n",
            "[63/100] Downloading: https://www.youtube.com/watch?v=Keqvv4jV5Tk\n",
            "[64/100] Downloading: https://www.youtube.com/watch?v=MYWpaNYAo0o\n",
            "[65/100] Downloading: https://www.youtube.com/watch?v=9HkQAyyYg2I\n",
            "[66/100] Downloading: https://www.youtube.com/watch?v=JxgmHe2NyeY\n",
            "[67/100] Downloading: https://www.youtube.com/watch?v=LB0kC0SkfeE\n",
            "[68/100] Downloading: https://www.youtube.com/watch?v=jGwO_UgTS7I\n",
            "[69/100] Downloading: https://www.youtube.com/watch?v=wRRaQWDRN-w\n",
            "[70/100] Downloading: https://www.youtube.com/watch?v=GLajwpGV630\n",
            "[71/100] Downloading: https://www.youtube.com/watch?v=ESTydJQ-SuU\n",
            "[72/100] Downloading: https://www.youtube.com/watch?v=JkZAQaUFNfU\n",
            "[73/100] Downloading: https://www.youtube.com/watch?v=scBPfEvMIJI\n",
            "[74/100] Downloading: https://www.youtube.com/watch?v=83Gh8XsfZMo\n",
            "[75/100] Downloading: https://www.youtube.com/watch?v=A--URhfnA7g\n",
            "[76/100] Downloading: https://www.youtube.com/watch?v=4Dn1vqg4Kc0\n",
            "[77/100] Downloading: https://www.youtube.com/watch?v=YU0S5jHSWFs\n",
            "[78/100] Downloading: https://www.youtube.com/watch?v=wvgjo-87aVA\n",
            "[79/100] Downloading: https://www.youtube.com/watch?v=it_9l0ADGzo\n",
            "[80/100] Downloading: https://www.youtube.com/watch?v=YZ8-GmTT7uM\n",
            "[81/100] Downloading: https://www.youtube.com/watch?v=39zbC_PrNQs\n",
            "[82/100] Downloading: https://www.youtube.com/watch?v=LXosuQEOLn0\n",
            "[83/100] Downloading: https://www.youtube.com/watch?v=soS0-OaFmls\n",
            "[84/100] Downloading: https://www.youtube.com/watch?v=yv87RU1MO6Q\n",
            "[85/100] Downloading: https://www.youtube.com/watch?v=lbEXe2tJ3MU\n",
            "[86/100] Downloading: https://www.youtube.com/watch?v=UfkCREqvlLg\n",
            "[87/100] Downloading: https://www.youtube.com/watch?v=KB-6eF2mnqY\n",
            "[88/100] Downloading: https://www.youtube.com/watch?v=NRTfJo4y3xs\n",
            "[89/100] Downloading: https://www.youtube.com/watch?v=5xp0taGM3Kg\n",
            "[90/100] Downloading: https://www.youtube.com/watch?v=LPZh9BOjkQs\n",
            "[91/100] Downloading: https://www.youtube.com/watch?v=uz6vFX91dg8\n",
            "[92/100] Downloading: https://www.youtube.com/watch?v=SL4FfHFGf0g\n",
            "[93/100] Downloading: https://www.youtube.com/watch?v=4b4MUYve_U8\n",
            "[94/100] Downloading: https://www.youtube.com/watch?v=OG7KqqMMicU\n",
            "[95/100] Downloading: https://www.youtube.com/watch?v=x8lcOwbdD8s\n",
            "[96/100] Downloading: https://www.youtube.com/watch?v=Pp_m-_9g8O4\n",
            "[97/100] Downloading: https://www.youtube.com/watch?v=ZXiruGOCn9s\n",
            "[98/100] Downloading: https://www.youtube.com/watch?v=vStJoetOxJg\n",
            "[99/100] Downloading: https://www.youtube.com/watch?v=ciLveEWIj5k\n",
            "[100/100] Downloading: https://www.youtube.com/watch?v=x20Kk6G0QkU\n",
            "🚀 All videos queued for conversion.\n",
            "\n",
            "\n",
            "✅ Pipeline complete: All videos downloaded and converted to audio.\n"
          ]
        }
      ]
    }
  ]
}